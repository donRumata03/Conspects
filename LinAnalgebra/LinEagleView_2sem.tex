\documentclass[12pt, a4paper]{article}

\input{../LatexGloves/latex_math_header.tex}


\title{Сжатый конспект по линейной алгебре \\(2-й семестр)} 

\author{
  \vova
  \and
  Кучерук Елена Аркадьевна (лектор)
}

\date{\today}



\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage


\section{Введение}

    Конспект старается быть максимальнго краткой выжимкой из того, 
    что нужно знать для успешной сдачи экзамена по Линейной Алгебре во втором семестре.

    Если кто-то сдаёт часть про линейные операторы и говтов по них написать, welcome.

\section{Сопряжённое пространство}

$V^*$ пространство линейных форм над $V$.

Вычисление формы на коордлинатном столбце $f(x) = \mathrm{x}^j a_j$, 
где строка $a_j$ размера n изоморфно сопоставляется форме.

— Координатные функции относительно базиса, $\omega^i(e_j) = \delta^i_j$.

Они базис $V^*$, так как их как раз $n$, а породить любую $f$ можно, предъявив коэффициенты $a_j$.

По $e$ мы научились находить сопряжённый базис, теперь научимся в обратную сторону 
находить по базису $V*$ такой базис $V$, чтобы исходный был к нему сопряжён:
возьмём любую сопряжённую пару $e, \omega$ 
и через это получим $\omega' → (e', \omega')$

Если назвать $S = T_{\omega → \omega'}^T$, утверждается, 
что можем получить $e'$ так: $T_{e → e'} = S^{-1}$

Чтобы доказать — проверим, что $\omega'$ — координатные функции $e'$.
То есть что координаты преобразуются правильно: $x' = S x$.

Элементы $V^*$ КОвариантные, так как преобразуются (получение новых из старых) 
с матрицей $T_{e → e'}$, 
а элементы $V$ — контравариантные, так как с матрицей $S = T^{-1}$

Доказывам, что можно получить изоморфизм 

\begin{equation}
    \varphi: V → (V^*)^*, x → "x" \quad \mathrm{where} "x"(f) = f(x)
\end{equation}

Кстати, $\varphi \in \Aut (V → (V^*)^*)$.

Линйеность $\varphi$ очевидна, для биективности в силу линейности 
достаточно проверить, что базис переходиь в базис (что $\rg \varphi = n$).
Действительно, $"e_j"$ — координатные функции базиса координатных функций, 
так как, $"e_j"(f) = f(e_j) = (a_f)_j$.

Отличие от $V \leftrightarrow V^*$ — в том, что теперь оно не зависит от выбора базиса.

— Умеем считать сопряжённый базис через обратную матрицу 
и матрицы проекторов через сопряжённый базис.



\section{Тензоры}

Это функция $V^p × (V^*)^q → \mathcal{K}$.

То, что «из векторов» — ковариантное, «из форм» — контрвариантное.

$T_{(p; q)}$ — линейное пространство размерности $n^(p + q)$

За счёт линейности при вычислении на наборе векторов, разложенных по базису,
можно вынести $p + q$ сумм с координатами, остаются значения тензора 
на разных размещениях базиса, их мы назовём компонентами относительно базисов $e, \omega$.

$\alpha^{j_1, …, j_q}_{i_1, …, i_p}$
Сверху пишется q «контравариантных индекса» — из форм.
Снизу — p ковариантные индексы — из векторов.

Это можно записать в $p + q$-мерную матрицу.

Смена базиса. Выразив старые координаты через новые 
($\xi^i = t^i_k {\xi'}^k, \eta_j = s^m_j {\eta'}_m$), 
подставим в формулу вычисления на наборе векторов, 
сгруппируем $t, s, \alpha$ скажем, что это новый компонент, 
а новые координаты как раз останутся.

Другое определение тензора: это многомерная матрица, 
в которой выделены «ковариантные» и «контравариантные» координаты 
и которая пересчитывается при смене базиса по той же формуле, что и выше.

Определения эквивалентны.

Тензорное произведение: вводим через второе определение 
(многомерная матрица), проверяем вариантность.

Говорим, что в терминах линейных форм мы берём 
каждую от своей части координат и перемножаем результаты.

Базис вводим базис $T_{(p; q)}$ 
из $n^{p + q}$ тензорных произведений всех размещений $e_i, \omega_j$,
помня, что 

\begin{gather*}
    \omega_j : (V)^1 → \mathcal{K} \\
    e_i \cong "e_i" : (V^*)^1 → \mathcal{K}
\end{gather*}

Доказываем, что это базис, так как количество $n^{p + q}$ 
и порождающее: за коэффициенты для порождения берём 
компоненты относительно базиса, доказываем через формулу вычисления на наборе векторов.

Заметим, что матрица тензора из базиса будет содержать одну единицу 
на соответствующих индексах и все остальные нули.

Вводим свёртку как матрицу, доказываем, что это тензор, помня, что 
$t_{\tilde{\kappa}}^{\kappa_{2}} s_{\kappa_{1}}^{\tilde{\kappa}} = \delta_{\kappa_{1}}^{\kappa_{2}}$ 
и оставляя в сумме только слагаемые, где $\kappa_{1}=\kappa_{2}=\kappa$.

Транспонирование: $\beta = \sigma(\alpha), \beta_{j_{1} \cdots j_{p}}^{i_{1} \cdots i_{q}}=\alpha_{j_{\sigma_{1}} \cdots j_{\sigma_{p}}}^{i_{1} \cdots i_{q}}$.

То есть набор индексов $\alpha$ переходит в индексы $\beta$ 
под действием обратной к $\sigma$ перестановки.

Доказываем, что тензор 
(достаточно доказать про транспозиции, 
так как перестановка раскладывается на композицию транспозиций) 

Заметим, что в терминах функций мы переставлем аргументы, тоже с обратной перестановкой.

Транспонирование — изоморфизм, ассоциативно, но коммутаитвно (как и группа перестановок).

Если при любом транспонировании тензора он не меняется, он симметричен, 
если умножается на $(-1)^{\varepsilon(\sigma)}$, то кососимметричен.

Кососимметричен $\Leftrightarrow$ равен нулю при повторяющихся аргументах.

Вводим симметрирование, альтенирование.

Оба перестановочны относительно перестановки, 
причём для симметрирования получается просто симметрирование,
а для альтенирования — оно умножить на знак перестановки.
(доказывается, используя, что если все перестановки $S_n$, по которым мы суммируем,
пропустить через одну перестановку, получим тоже все перестановки, но в другом порядке — таблица Кэли, иначе не группа)

$\alpha$ симметричен $\Leftrightarrow \alpha = \Sim \alpha$.
$\alpha$ КОСОсимметричен $\Leftrightarrow \alpha = \Alt \alpha$.

Обе идемпотентны, причём $\Sim \Alt \alpha = 0$ 
(то есть симметрирование любого кососимметричного — ноль, ведь можно подставить кососимметричный
$\beta = \Alt \beta$, тогда $\Sim \beta = \Sim \Alt \beta = 0$).

Доказывается, заметив, что сумма чётностей по всем перестановкам — это ноль, 
так как это определитель матрицы со всеми единицами.

Заметим, что пересечение подпространств симметричных и антисимметричных тензоров — тривиально.
Более того, если транспозиция одна (по двум индексам), 
то пространство всех тензоров заданного типа раскладвыаются в дизъюнктную сумму симметричных и антисимметричных (по этим индексам), 
где $\alpha = \Sim \alpha + \Alt \alpha$

\subsection{p-формы}

$p$-формы — антисимметричные ковариантные тензоры, Если от одного аргумента, отождествляют с $V^*$.

Внешнее произведение: $f \land g = \frac{(p_f + p_g)!}{p_f! p_g!} \Alt (f \otimes g)$.

Есть свойства, можно через них раскрывать скобки.

1. $f \wedge g=(-1)^{p_{1} p_{2}} g \wedge f$.
2. $(f+g) \wedge h=f \wedge h+g \wedge h$ и $f \wedge(g+h)=f \wedge g+f \wedge h$.
3. $\lambda \cdot(f \wedge g)=(\lambda f) \wedge g=f \wedge(\lambda g)$.
4. $\mathbb{D}_{\Lambda^{p_{1}} V^{*}} \wedge g=f \wedge \mathbb{\mathbb { D }}_{\Lambda^{p_{2}} V^{*}}=\mathbb{D}_{\Lambda^{p_{1}+p_{2}} V^{*}}$.
5. $(f \wedge g) \wedge h=f \wedge(g \wedge h)=\frac{\left(p_{1}+p_{2}+p_{3}\right) !}{p_{1} ! p_{2} ! p_{3} !} \operatorname{Alt}(f \otimes g \otimes h)$.

2, 3, 4 — очевидно.

1 — записываем по определению, сопоставляем у сумм слагаемые, 
смотрим на количество инверсий между ними, оно как раз $p_f p_g$.

5 — по определению, доказываем, что $\Alt(\Alt(f \otimes g) \otimes h) = \Alt(f \otimes \operatorname{Alt}(g \otimes h)) = \Alt(f \otimes g \otimes h)$.
По линейности заносим второе тензорное произведение под внутреннюю сумму, 
потом создаём перестановку, работающую на всех трёх наборах индексов, но переставляющую только первые два как $\sigma$,
по линейности альтенирования заносим его под сумму, замечаем альтенирование от перестановки, сокращаем $(-1)$, конец.

По индукции можно обобщить формулу для внешнего произведения на несколько векторов.


Есть базис пространства антисимметричных $p$-форм (антисимметричных тензоров) 
размера $\begin{pmatrix} n \\ p \end{pmatrix}$ из врешних произведений 
упорядоченных комбинаций кординатных функций. 
Координаты в нём называют существенными, они численно совпадают 
с координатой для того же набора в пространстве всех тензоров.


Можно вычислить значение внешнего произведения 1-форм на наборе векторов через определитель 
матрицы применения каждой функции к каждому вектору.

Также можно найти координаты внешнего произведения в базисе внешних произведений, 
если знаем разложение самих функций по базису пространства линейных форм.

Комбинируя, можно через сумму произведений двух соответствующих опредеителей 
вычислить функцию, заданную произведением $1$-форм, заданных координатами, 
на наборе векторов, заданных координатами.


\section{Евклидовы пространства}

Скалярное (линейные пространства над вещественными числами) — функция от двух векторов: 
симметричность, линейность по первому ($\Rightarrow$ каждому) аргументу, 
положительная определённость.

Псевдоскалярное (линейные пространства над комплексными числами): 
то же самое, только симметричность — эрмитова и по второму аргменту становится 
«эрмитова» однородность, хотя и нормальная аддитивность.

Евклидова норма — корень из скалярного квадрата.

КБШ: $| \langle x, y \rangle | \leqslant ||x|| ||y||$, причём равенство только при линейной зависимости.
Доказываем так: берём положительное $\langle \alpha x + \beta y, \alpha x + \beta y \rangle$, раскрываем, подставляем
$\alpha = <y, y>, \beta = -<x, y>$, выносим $||y||$, получаем, что искомое положительно.
Из равенства в КБШ сдедует зависимость, так как мы берём вот эти альфа и бета, получаем скалярный квадрат ноль.
Из зависимости следует равенство: берём $\alpha x + \beta y = 0$ по определению л.з., 
рассматриваем $\langle\alpha x+\beta y, x\rangle=0; \langle\alpha x+\beta y, y\rangle=0$, раскрываем, перемножаем равенства, конец.

Проверка свойств норм для Евклидовой нормы:
Положительная определённость, однородность — очевидно. 
Нер-во треугольника: доказываем про квадраты норм, раскрывая $||x + y||^2$, замечая сумму сопряжённых, применяя КБШ и получая полный квадрат.

Ортогональая система — линейно независима. Доказвается, скалярно умножая нулевую линейную комибнацию на базисный вектор, 
по ортогональности остаётся толко его компонент. 


Грам-Шмидт: систему векторов можно заменить на ортогональную систему не большего размера с сохранением линейной оболочки.
Процессируя очередной вектор, будем вычитать линейную комбинацию предыдущих, уже ортогональных. Так, чтобы новый стал ортогонален каждому.
Если на каком-то шаге получится ноль, выкинем его.

Ортонормированную систему можно дополнить до ОНБ.

Примеры: коэффициенты Фурье, полиномы Лежандра.

Формула Родрига: $\tilde{e_k} = \lambda_k \left( (x^2 - 1)^k \right)^(k)$.

Доказываем, что $\tilde{e_k} \perp x^m \forall m < k$. Берём интегралл, много раз интегрируя по частям, уменьшая степень $x^m$ и уменьшая количество дифференцирований у $\tilde{e_k}$
каждый раз подстановка обнуляется, так как \textit{Если полином имеет корень кратности $k$, этот корень — кратности $k - 1$ у производной}.

Общая формула Родрига (хотя почему общая?…). Если взять $\lambda_k = \frac{1}{2^k k!}$, то $\tilde{e_k}(1) = 1$. 
Для доказательства вычислим $\tilde{e_k}(1)$ по формуле Лейбница для произведения $(x - 1)^k (x + 1)^k$, где слагаемые для $i != k$ обнуляются.

Квадрат нормы полиномов будет $\frac{2}{2k + 1}$ (опять интегрируеим по частям, уменьшая степень у одного и поднимая у другого).

Полиномы Чёбышева. Скалярное произведение — с весом $\frac{1}{\sqrt{1 - x^2}}$, получаем $T_n = \cos(n \cos^{-1}(x))$.
Доказываем, что это полиномы по индукции, что $T_{n + 1} + T_{n - 1} = 2x T_n$.

Полиномы Эрмита. Скалярное произведение — от нуля до $+\infty$ с весом $e^{-x^2}$.
$H_n = e^{x^2} \left( e^{-x^2} \right)^(n)$.

Скалярное произведение в кооринатах: через матрицу Грама для базиса, $\left\langle x, y \right\rangle = x^T \Gamma \overline{y}$.
Для ортонормированного — матрица единичная.

Матрица Грама сомосопряжена.

Теорема об определителе матрицы Грама: если система зависима, он равен нулю, 
иначе — произведению скалярных квадратов векторов, получающихся ортогонализацией Грама-Шмидта.

Доказывается, вычитанием в определителе $g(…, a_i, …)$ соответствующих линейных комбинаций одновременно из строк и столбцов 
$\rightsquigarrow$ на каждом шаге все $a_i$ в матрице заменяются на $b_i$. Получаем определитель ортогональной системы, то есть $| \diag (b_i) |$.

Можем посчитать норму ортогонализации нового вектора через отношение матриц нового и старого определителя, если исходная система независима.

Объём параллелепипеда — корень из определителя Грама.

Можно вычислить матрицу Грама системы так: $G(a_1, …, a_i) = A^T \Gamma \overline{A}$. Для ОНБ, понятно, $\Gamma$ убирается.

Причём, если количество векторов равно размерности пространства, а $\Gamma = E$, объём — это просто определитель матрицы координат.

Объём под действием оператора изменяется в $\det \mathcal{B}$ раз (как определитель системы векторов при применении оператора). 
Например, при повороте объём сохраняется, а при гомотетии растёт в $\lambda$ раз.

Матрица Грама базиса положительно определённая, её угловые миноры больше нуля.
Она преобразуется при смене базиса: $\Gamma' = T^T \Gamma \overline{T}$. 
(Доказывается через смену координат в формуле для скалярного произведения и подстановку $x' = e_i, y' = e_j'$, ведь мы уже получили, 
что скалярное произведение элементов считается через эту матрицу, а значит, и для базисных векторов это тоже верно).



Изометрическая матрица: обратна сопряжению.

Свойства: 

\begin{enumerate}
    \item Изометричность равносильна ортонормированности столбцов, как и строк ($\Gamma = E$). Доказыввается через $Q^T \overline{Q} = E$, что соответствует $\langle q_i, q_j \rangle = \delta^i_j$
    \item $Q$ — изометрично $\Leftrightarrow$ $Q^{-1}$ — изометрично 
    \item Произведение изометричных изометрично
    \item $| \det Q | = 1$
    \item Матрица перехода между ОНБ — изометрична (по формуле для $\Gamma'$).
\end{enumerate} 


Ортогональное дополнение


Почему $V = L \oplus L^{\perp}$

Расстояние от точки до линейного многообразия. Через отношение определителей матриц Грама. Задание 1374



\section{Расстояние до многообразия}

Можно найти используя отношения определителей матрицы Грама.

Матрица грамма в новом базисе: $\Gamma' = T^T \Gamma \overline{T}$

Между многообразиями: $dist(x_1 - x_2; L_1 + L_2)$.

$dist^2(x, L) = \frac{g(…, x)}{g(…)}$

\section{Страсти по операторам}

\subsection{Сопряжённый}

Матрица $\overline{\Gamma^{-1}} A^* \overline{\Gamma}$, в онб — просто $A^*$
Сопряжение — взаимообратно.
Отнсительно компоиции — как транспонирование.
Аддитивность, псевдоОднородность.
Перестановочность относительно $(.)^{-1}$

Ядро оператора и образ сопряжённого — ортогональные дополнения друг друга, как и образ оператора и ядро сопряжённого.


Собственные числа — сопряжения друг друга.
Для не соответствующих — собственные векторы ортогональны, для соответствующих — одинаковые.

Если подпространство инвариантно относительно A, то его ортогональное дополнение — относительно A*.


\subsection{Нормальный}

$\Longleftrightarrow$ Перестановочен с сопряжённым 
$\Longleftrightarrow$ $\langle A x, A y \rangle = \langle A^* x, A^* y \rangle$ 
$\Longleftrightarrow$ В некотором базисе матрицы перестановочны
$\Longleftrightarrow$ ОПС + собственные пространства ортогональны 
$\Longleftrightarrow$ Существует какой-нибудь ОНБ, что матрица имеет понятно какой блочно-диагональный вид


Не перестанет быть нормальным, если вычесть сколько-то id.

У нормального оператора ядро и образ — ортогональные дополнения друг друга (если удалось получить собственные числа из того же поля, то потому, что это собственное подпространство нуля и все остальные).

Причём ядро не меняется при возведении в степень. И $\Ker A = \Ker A*$.

Лемма о комплексификации (оператора):

— Собственные числа сохранются, собственные пропртанства будут комплексификацией соответствующих
— Комлексные собственные числа и простанства будут разбиваться на пары сопряжённых.
— Нормальность сохраняется
— Сопряжённость — перестановочная с комплексификацией

(Лемма очевидна, если учесть, что любое полиномиальное уравнение, верное в подполе, верно и в самом поле)


Канонический вид:
— В унитарном: находим ОНБ из собственных подпространств, получаем собственные числа на диаонали

— В евклидовом: если все СЧ — вещ. — аналогично. Иначе — добавляем ещё блоки для пар комплексно-сопряжённых.
Матрица перехода всё ещё должна быть ортогональная. Как её найти? Для вещественных собственных чисел — просто собственные векторы. 
Для пар КС разделяем какой-нибудь вектор на пару вещественной и комплексной части и запишем в таком порядке.


\section{Самосопряжённый}

(симметричный/эрмитов)

Равносильное определение через скалярное произведение: применить можно как к первому, так и ко второму аргументу, получится то же самое.
И в обратную сторону.

Если A и B САМОсопряжены и перестановочны, то произведение самосопряжено.

Самосопряжён 
<=> нормален + имеет вещественный спектр
<=> существует ОНБ, в котором матрица самосопряжена

Если подпространство инвариантно относительно А, то и ортогональное дополнение — тоже.

В каноническом виде просто пропадут блоки, останутся просто (и в унитарном, и в Евклидовом)


\section{Изометричный}

Унитарный/ортогональный

Равносильное определение через скалярное произведение, что если применить к обоим аргументам, скалярное проиведение не изменится.



…
$\Longleftrightarrow$ нормален + собственные числа по модулю = 1
$\Longleftrightarrow$ существует ОНБ, в котором матрица изометрична
$\Longleftrightarrow$ $Q^{-1}$ — изометр.

Если подпространство инвариантно относительно $Q$, то орт. дополнение — тоже.

Каноничечкий вид
— В Евклидовом на диагонали останутся только $± 1$
— В Унтарном в блоках будут $a^2 + b^2 = 1$

Матрица изометрична $\Longleftrightarrow$ её (стобцы $\Longleftrightarrow$ строки) ортонормированы.


\section{Разложения}

$L(D)U$ — нижне-унитреугольная * (Диагональная без нулей на диагонали) * верхне-унитреугольная; 
Существует $\Longleftrightarrow$ Все угловые миноры матрицы A, кроме (возможно) $∆_n$ не равны нулю. 
Можно найти одновременным Гауссом $A$ и $E$ без замены строк и столбцов. Слева будет $DU$, справа — $L^{-1}$

Если матрица сомосопряжённая, будет $A = LDL^* = U^*DU$. Причём все $d$ вещественные.

Положительная/отрицаельная определённость, то же самое про собственные числа

Разложение Холецкого: самосопряжённая положительно определённая, все угловые миноры кроме, возможно, последнего, не нули $\Longleftrightarrow$ можно убрать $D$, 
разложить на треугольные с положительными элементами на диагонали.

$QR$ разложение: для невырожденной можно представить как произведение ортогональной на правую. Или же левой на ортогональную.
$Q$ находится ортонормированием столбцов исходной.

Полярное ($QS$ или $SQ$) разлжение: на самосопряжённую (H) положительно определённую и ортогональную (U). 
Нужно взять $\sqrt{AA*}$ (левый модуль) для получения ортогонального. Далее — через обратную.

Можно также UH, тогда берём $H = \sqrt{A*A}$ (правый модуль).





\end{document}
