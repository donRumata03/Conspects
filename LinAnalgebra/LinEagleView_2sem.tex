\documentclass[12pt, a4paper]{article}

\input{../LatexGloves/latex_math_header.tex}


\title{Сжатый конспект по линейной алгебре \\(2-й семестр)} 

\author{
  \vova
  \and
  Кучерук Елена Аркадьевна (лектор)
}

\date{\today}



\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage


\section{Введение}

    Конспект старается быть максимальнго краткой выжимкой из того, 
    что нужно знать для успешной сдачи экзамена по Линейной Алгебре во втором семестре.

    Если кто-то сдаёт часть про линейные операторы и говтов по них написать, welcome.

\section{Сопряжённое пространство}

$V^*$ пространство линейных форм над $V$.

Вычисление формы на коордлинатном столбце $f(x) = \mathrm{x}^j a_j$, 
где строка $a_j$ размера n изоморфно сопоставляется форме.

— Координатные функции относительно базиса, $\omega^i(e_j) = \delta^i_j$.

Они базис $V^*$, так как их как раз $n$, а породить любую $f$ можно, предъявив коэффициенты $a_j$.

По $e$ мы научились находить сопряжённый базис, теперь научимся в обратную сторону 
находить по базису $V*$ такой базис $V$, чтобы исходный был к нему сопряжён:
возьмём любую сопряжённую пару $e, \omega$ 
и через это получим $\omega' → (e', \omega')$

Если назвать $S = T_{\omega → \omega'}^T$, утверждается, 
что можем получить $e'$ так: $T_{e → e'} = S^{-1}$

Чтобы доказать — проверим, что $\omega'$ — координатные функции $e'$.
То есть что координаты преобразуются правильно: $x' = S x$.

Элементы $V^*$ КОвариантные, так как преобразуются (получение новых из старых) 
с матрицей $T_{e → e'}$, 
а элементы $V$ — контравариантные, так как с матрицей $S = T^{-1}$

Доказывам, что можно получить изоморфизм 

\begin{equation}
    \varphi: V → (V^*)^*, x → "x" \quad \mathrm{where} "x"(f) = f(x)
\end{equation}

Кстати, $\varphi \in \Aut (V → (V^*)^*)$.

Линйеность $\varphi$ очевидна, для биективности в силу линейности 
достаточно проверить, что базис переходиь в базис (что $\rg \varphi = n$).
Действительно, $"e_j"$ — координатные функции базиса координатных функций, 
так как, $"e_j"(f) = f(e_j) = (a_f)_j$.

Отличие от $V \leftrightarrow V^*$ — в том, что теперь оно не зависит от выбора базиса.

— Умеем считать сопряжённый базис через обратную матрицу 
и матрицы проекторов через сопряжённый базис.



\section{Тензоры}

\subsection{Два определения, смена базиса}

Это функция $V^p × (V^*)^q → \mathcal{K}$.

То, что «из векторов» — ковариантное, «из форм» — контрвариантное.

$T_{(p; q)}$ — линейное пространство размерности $n^(p + q)$

За счёт линейности при вычислении на наборе векторов, разложенных по базису,
можно вынести $p + q$ сумм с координатами, остаются значения тензора 
на разных размещениях базиса, их мы назовём компонентами относительно базисов $e, \omega$.

$\alpha^{j_1, …, j_q}_{i_1, …, i_p}$
Сверху пишется q «контравариантных индекса» — из форм.
Снизу — p ковариантные индексы — из векторов.

Это можно записать в $p + q$-мерную матрицу.

Смена базиса. Выразив старые координаты через новые 
($\xi^i = t^i_k {\xi'}^k, \eta_j = s^m_j {\eta'}_m$), 
подставим в формулу вычисления на наборе векторов, 
сгруппируем $t, s, \alpha$ скажем, что это новый компонент, 
а новые координаты как раз останутся.

Другое определение тензора: это многомерная матрица, 
в которой выделены «ковариантные» и «контравариантные» координаты 
и которая пересчитывается при смене базиса по той же формуле, что и выше.

Определения эквивалентны.

\subsection{Тензорное произведение, свёртка, транспонирование}

Тензорное произведение: вводим через второе определение 
(многомерная матрица), проверяем вариантность.

Говорим, что в терминах линейных форм мы берём 
каждую от своей части координат и перемножаем результаты.

Базис вводим базис $T_{(p; q)}$ 
из $n^{p + q}$ тензорных произведений всех размещений $e_i, \omega_j$,
помня, что 

\begin{gather*}
    \omega_j : (V)^1 → \mathcal{K} \\
    e_i \cong "e_i" : (V^*)^1 → \mathcal{K}
\end{gather*}

Доказываем, что это базис, так как количество $n^{p + q}$ 
и порождающее: за коэффициенты для порождения берём 
компоненты относительно базиса, доказываем через формулу вычисления на наборе векторов.

Заметим, что матрица тензора из базиса будет содержать одну единицу 
на соответствующих индексах и все остальные нули.

Вводим свёртку как матрицу, доказываем, что это тензор, помня, что 
$t_{\tilde{\kappa}}^{\kappa_{2}} s_{\kappa_{1}}^{\tilde{\kappa}} = \delta_{\kappa_{1}}^{\kappa_{2}}$ 
и оставляя в сумме только слагаемые, где $\kappa_{1}=\kappa_{2}=\kappa$.

Транспонирование: $\beta = \sigma(\alpha), \beta_{j_{1} \cdots j_{p}}^{i_{1} \cdots i_{q}}=\alpha_{j_{\sigma_{1}} \cdots j_{\sigma_{p}}}^{i_{1} \cdots i_{q}}$.

То есть набор индексов $\alpha$ переходит в индексы $\beta$ 
под действием обратной к $\sigma$ перестановки.

Доказываем, что тензор 
(достаточно доказать про транспозиции, 
так как перестановка раскладывается на композицию транспозиций) 

Заметим, что в терминах функций мы переставлем аргументы, тоже с обратной перестановкой.

Транспонирование — изоморфизм, ассоциативно, но коммутаитвно (как и группа перестановок).

Если при любом транспонировании тензора он не меняется, он симметричен, 
если умножается на $(-1)^{\varepsilon(\sigma)}$, то кососимметричен.

Кососимметричен $\Leftrightarrow$ равен нулю при повторяющихся аргументах.

\subsection{Симметрирование, альтенирование}

Оба перестановочны относительно перестановки, 
причём для симметрирования получается просто симметрирование,
а для альтенирования — оно умножить на знак перестановки.
(доказывается, используя, что если все перестановки $S_n$, по которым мы суммируем,
пропустить через одну перестановку, получим тоже все перестановки, но в другом порядке — таблица Кэли, иначе не группа)

$\alpha$ симметричен $\Leftrightarrow \alpha = \Sim \alpha$.
$\alpha$ КОСОсимметричен $\Leftrightarrow \alpha = \Alt \alpha$.

Обе идемпотентны, причём $\Sim \Alt \alpha = 0$ 
(то есть симметрирование любого кососимметричного — ноль, ведь можно подставить кососимметричный
$\beta = \Alt \beta$, тогда $\Sim \beta = \Sim \Alt \beta = 0$).

Доказывается, заметив, что сумма чётностей по всем перестановкам — это ноль, 
так как это определитель матрицы со всеми единицами.

Заметим, что пересечение подпространств симметричных и антисимметричных тензоров — тривиально.
Более того, если транспозиция одна (по двум индексам), 
то пространство всех тензоров заданного типа раскладвыаются в дизъюнктную сумму симметричных и антисимметричных (по этим индексам), 
где $\alpha = \Sim \alpha + \Alt \alpha$

\subsection{p-формы}

$p$-формы — антисимметричные ковариантные тензоры, Если от одного аргумента, отождествляют с $V^*$.

Внешнее произведение: $f \land g = \frac{(p_f + p_g)!}{p_f! p_g!} \Alt (f \otimes g)$.

Есть свойства, можно через них раскрывать скобки.

1. $f \wedge g=(-1)^{p_{1} p_{2}} g \wedge f$.
2. $(f+g) \wedge h=f \wedge h+g \wedge h$ и $f \wedge(g+h)=f \wedge g+f \wedge h$.
3. $\lambda \cdot(f \wedge g)=(\lambda f) \wedge g=f \wedge(\lambda g)$.
4. $\mathbb{D}_{\Lambda^{p_{1}} V^{*}} \wedge g=f \wedge \mathbb{\mathbb { D }}_{\Lambda^{p_{2}} V^{*}}=\mathbb{D}_{\Lambda^{p_{1}+p_{2}} V^{*}}$.
5. $(f \wedge g) \wedge h=f \wedge(g \wedge h)=\frac{\left(p_{1}+p_{2}+p_{3}\right) !}{p_{1} ! p_{2} ! p_{3} !} \operatorname{Alt}(f \otimes g \otimes h)$.

2, 3, 4 — очевидно.

1 — записываем по определению, сопоставляем у сумм слагаемые, 
смотрим на количество инверсий между ними, оно как раз $p_f p_g$.

5 — по определению, доказываем, что $\Alt(\Alt(f \otimes g) \otimes h) = \Alt(f \otimes \operatorname{Alt}(g \otimes h)) = \Alt(f \otimes g \otimes h)$.
По линейности заносим второе тензорное произведение под внутреннюю сумму, 
потом создаём перестановку, работающую на всех трёх наборах индексов, но переставляющую только первые два как $\sigma$,
по линейности альтенирования заносим его под сумму, замечаем альтенирование от перестановки, сокращаем $(-1)$, конец.

По индукции можно обобщить формулу для внешнего произведения на несколько векторов.


Есть базис пространства антисимметричных $p$-форм (антисимметричных тензоров) 
размера $\begin{pmatrix} n \\ p \end{pmatrix}$ из врешних произведений 
упорядоченных комбинаций кординатных функций. 
Координаты в нём называют существенными, они численно совпадают 
с координатой для того же набора в пространстве всех тензоров.


Можно вычислить значение внешнего произведения 1-форм на наборе векторов через определитель 
матрицы применения каждой функции к каждому вектору.

Также можно найти координаты внешнего произведения в базисе внешних произведений, 
если знаем разложение самих функций по базису пространства линейных форм.

Комбинируя, можно через сумму произведений двух соответствующих опредеителей 
вычислить функцию, заданную произведением $1$-форм, заданных координатами, 
на наборе векторов, заданных координатами.


\section{Евклидовы пространства}

\subsection{Аксиомы, КБШ}

Скалярное (линейные пространства над вещественными числами) — функция от двух векторов: 
симметричность, линейность по первому ($\Rightarrow$ каждому) аргументу, 
положительная определённость.

Псевдоскалярное (линейные пространства над комплексными числами): 
то же самое, только симметричность — эрмитова и по второму аргменту становится 
«эрмитова» однородность, хотя и нормальная аддитивность.

Евклидова норма — корень из скалярного квадрата.

КБШ: $| \langle x, y \rangle | \leqslant ||x|| ||y||$, причём равенство только при линейной зависимости.
Доказываем так: берём положительное $\langle \alpha x + \beta y, \alpha x + \beta y \rangle$, раскрываем, подставляем
$\alpha = <y, y>, \beta = -<x, y>$, выносим $||y||$, получаем, что искомое положительно.
Из равенства в КБШ сдедует зависимость, так как мы берём вот эти альфа и бета, получаем скалярный квадрат ноль.
Из зависимости следует равенство: берём $\alpha x + \beta y = 0$ по определению л.з., 
рассматриваем $\langle\alpha x+\beta y, x\rangle=0; \langle\alpha x+\beta y, y\rangle=0$, раскрываем, перемножаем равенства, конец.

Проверка свойств норм для Евклидовой нормы:
Положительная определённость, однородность — очевидно. 
Нер-во треугольника: доказываем про квадраты норм, раскрывая $||x + y||^2$, замечая сумму сопряжённых, применяя КБШ и получая полный квадрат.

Ортогональая система — линейно независима. Доказвается, скалярно умножая нулевую линейную комибнацию на базисный вектор, 
по ортогональности остаётся толко его компонент. 

\subsection{Грам-Шмидт, примеры}

Грам-Шмидт: систему векторов можно заменить на ортогональную систему не большего размера с сохранением линейной оболочки.
Процессируя очередной вектор, будем вычитать линейную комбинацию предыдущих, уже ортогональных. Так, чтобы новый стал ортогонален каждому.
Если на каком-то шаге получится ноль, выкинем его.

Ортонормированную систему можно дополнить до ОНБ.

Примеры: коэффициенты Фурье, полиномы Лежандра.

Формула Родрига: $\tilde{e_k} = \lambda_k \left( (x^2 - 1)^k \right)^(k)$.

Доказываем, что $\tilde{e_k} \perp x^m \forall m < k$. Берём интегралл, много раз интегрируя по частям, уменьшая степень $x^m$ и уменьшая количество дифференцирований у $\tilde{e_k}$
каждый раз подстановка обнуляется, так как \textit{Если полином имеет корень кратности $k$, этот корень — кратности $k - 1$ у производной}.

Общая формула Родрига (хотя почему общая?…). Если взять $\lambda_k = \frac{1}{2^k k!}$, то $\tilde{e_k}(1) = 1$. 
Для доказательства вычислим $\tilde{e_k}(1)$ по формуле Лейбница для произведения $(x - 1)^k (x + 1)^k$, где слагаемые для $i != k$ обнуляются.

Квадрат нормы полиномов будет $\frac{2}{2k + 1}$ (опять интегрируеим по частям, уменьшая степень у одного и поднимая у другого).

Полиномы Чёбышева. Скалярное произведение — с весом $\frac{1}{\sqrt{1 - x^2}}$, получаем $T_n = \cos(n \cos^{-1}(x))$.
Доказываем, что это полиномы по индукции, что $T_{n + 1} + T_{n - 1} = 2x T_n$.

Полиномы Эрмита. Скалярное произведение — от нуля до $+\infty$ с весом $e^{-x^2}$.
$H_n = e^{x^2} \left( e^{-x^2} \right)^(n)$.


\subsection{Матрица Грама, её определитель}

Скалярное произведение в кооринатах: через матрицу Грама для базиса, $\left\langle x, y \right\rangle = x^T \Gamma \overline{y}$.
Для ортонормированного — матрица единичная.

Матрица Грама сомосопряжена.

Теорема об определителе матрицы Грама: если система зависима, он равен нулю, 
иначе — произведению скалярных квадратов векторов, получающихся ортогонализацией Грама-Шмидта.

Доказывается, вычитанием в определителе $g(…, a_i, …)$ соответствующих линейных комбинаций одновременно из строк и столбцов 
$\rightsquigarrow$ на каждом шаге все $a_i$ в матрице заменяются на $b_i$. Получаем определитель ортогональной системы, то есть $| \diag (b_i) |$.

Можем посчитать норму ортогонализации нового вектора через отношение матриц нового и старого определителя, если исходная система независима.

Объём параллелепипеда — корень из определителя Грама.

Можно вычислить матрицу Грама системы так: $G(a_1, …, a_i) = A^T \Gamma \overline{A}$. Для ОНБ, понятно, $\Gamma$ убирается.

Причём, если количество векторов равно размерности пространства, а $\Gamma = E$, объём — это просто определитель матрицы координат.

Объём под действием оператора изменяется в $\det \mathcal{B}$ раз (как определитель системы векторов при применении оператора). 
Например, при повороте объём сохраняется, а при гомотетии растёт в $\lambda$ раз.

Матрица Грама базиса положительно определённая, её угловые миноры больше нуля.
Она преобразуется при смене базиса: $\Gamma' = T^T \Gamma \overline{T}$. 
(Доказывается через смену координат в формуле для скалярного произведения и подстановку $x' = e_i, y' = e_j'$, ведь мы уже получили, 
что скалярное произведение элементов считается через эту матрицу, а значит, и для базисных векторов это тоже верно).

\subsection{Изометрическая матрица}

Изометрическая матрица: обратна сопряжению.

Свойства: 

\begin{enumerate}
    \item Изометричность равносильна ортонормированности столбцов, как и строк ($\Gamma = E$). 
    Доказыввается через $Q^T \overline{Q} = E$, что соответствует $\langle q_i, q_j \rangle = \delta^i_j$
    \item $Q$ — изометрично $\Leftrightarrow$ $Q^{-1}$ — изометрично 
    \item Произведение изометричных изометрично
    \item $| \det Q | = 1$
    \item Матрица перехода между ОНБ — изометрична (по формуле для $\Gamma'$).
\end{enumerate} 

\subsection{Ортогональное дополнения, расстояния}

$L^{\perp}$ — ортогональное дополнение $L$ — мн-во векторов, ортогональным всем векторам $L$.

Это линейное подпространство, $L \cap L^{\perp} = \{\mathbb{0}\}$, причём $L \oplus L^{\perp} = V$. 
(Для док-ва дополним онб $L$ до онб $V$. Подпространство, натянутое на добавленные векторы является прямым дополнением $L$, 
причём в сумме — онб, то есть любой вектор из дополнения ортогонален $L$, то есть полученное дополнение содержится в $L^{\perp}$,
причём $\dim L^{\perp} \leqslant \dim V - \dim L$, так как иначе бы их пересечение было нетривиально)

${L^\perp}^\perp = L$ — доказываем подмножественность и равенство размерностей.

$(L_1 + L_2)^\perp = L_1^\perp \cap L_2\perp; (L_1 \cap L_2)^\perp = L_1^\perp + L_2\perp$. 
Доказываем прямое и обратное включение, подставляя нули в качестве некоторых векторов.
Второе следует из первого.

Единственность представления вектора как сумму составляющих из $L$ и $L^\perp$: $x = y + z$. 
(Едиственность и так известна из дизъюнктности, но здесь есть хороший способ поиска).
Найдём разложение составляющей из $L$ по базису $L$. Составим СНЛУ, что $\langle x, l_i \rangle = \langle y, l_i \rangle$,
раскрыв это по разложению с кроэффициентами $c_i$ и линейности.
Получим СЛНУ с единственным решением за счёт $det G \neq 0$:

\begin{equation}
    G(l_1, …, l_{\dim L})^T \mathbb{c} = \langle \mathbb{x, l} \rangle
\end{equation}

Теорема Пифагора: для перпендикулярных векторов квадрат суммы — это сумма квадратов, так как смешанные слагаемые обнуляются.
Можно также обобщить на n перпендикулярных векторов.

Теорема о наилучшем приближении: ортогональная проекция — самый близкий элемент $L$ к исходному вектору. (Из Пифагора)

Расстояния между точкой и линейным пространством, точкой и многообразием, двумя многообразиями.

$dist^2(x, L) = \frac{g(…, x)}{g(…)}$, так как при ортогонализации в числителе $x$ превратится в компоненту относительно $L^{\perp}$

Для многообразия $\rho(x, [P = x_0 + L]) = \rho(x - x_0, L)$, доказывается через резложение $x - x_0 = y + z$ и примерение теоремы Пифагора.

$\rho([P_1 = x_1 + L_1], [P_2 = x_2 + L_2]) = \rho(x_1 - x_2, L_1 + L_2)$, так как 

\begin{equation}
    \min_{\substack{l_{1} \in L_{1} \\ l_{2} \in L_{2}}} \left\| x_1 - x_2 + l_1 - l_2\right\| = 
    \min_{l \in L_{1}+L_{2}} \left\|x_1 - x_2 + l\right\|
\end{equation}

Пространство можно разложить в прямую сумму попорно ортогональных подпространств.
Если они все размерности 1, можно найти коэффициенты по Формуде Фурье: $x_i = \frac{\langle x, e_i \rangle}{\langle e_i, e_i \rangle}$ (просто скалярно домножили разложение в ОБ на $e_i$).

Тождество Парсеваля: в ортогоналном базисе $||x||^2 = \sum |x_i| ||e_i||^2$ (по теореме Пифагора)
(Для бесконечномерных будет только неравенство БесселяЖ будет знак $\leqslant$)

Мы также можем строить проекторы на одномерные ортогональные пространства через склярные произведения с элементами базиса (коэффициенты Фурье).

\subsection{Изометрия $V$ и $V^{*}$}

Пространства изометричны — существует изоморфизм с сохранением скалярного произведения.

На любых евкл/унит прострснствах одной размерности можно ввести изометрию: 
сопоставляем векторы с одинаковыми коэффициентами в разложениях фиксированных \textbf{ОНБ}. 
Понятно, что такая изометрия зависит от выбора базисов.

Теорема Рисса.

\subsection{Метрические тензоры, взаимные базисы}



\section{Операторы в Евкливых пространствах}

\subsection{Сопряжённый}

Матрица $\overline{\Gamma^{-1}} A^* \overline{\Gamma}$, в онб — просто $A^*$
Сопряжение — взаимообратно.
Отнсительно компоиции — как транспонирование.
Аддитивность, псевдоОднородность.
Перестановочность относительно $(.)^{-1}$

Ядро оператора и образ сопряжённого — ортогональные дополнения друг друга, как и образ оператора и ядро сопряжённого.


Собственные числа — сопряжения друг друга.
Для не соответствующих — собственные векторы ортогональны, для соответствующих — одинаковые.

Если подпространство инвариантно относительно A, то его ортогональное дополнение — относительно A*.


\subsection{Нормальный}

$\Longleftrightarrow$ Перестановочен с сопряжённым 
$\Longleftrightarrow$ $\langle A x, A y \rangle = \langle A^* x, A^* y \rangle$ 
$\Longleftrightarrow$ В некотором базисе матрицы перестановочны
$\Longleftrightarrow$ ОПС + собственные пространства ортогональны 
$\Longleftrightarrow$ Существует какой-нибудь ОНБ, что матрица имеет понятно какой блочно-диагональный вид


Не перестанет быть нормальным, если вычесть сколько-то id.

У нормального оператора ядро и образ — ортогональные дополнения друг друга (если удалось получить собственные числа из того же поля, то потому, что это собственное подпространство нуля и все остальные).

Причём ядро не меняется при возведении в степень. И $\Ker A = \Ker A*$.

Лемма о комплексификации (оператора):

— Собственные числа сохранются, собственные пропртанства будут комплексификацией соответствующих
— Комлексные собственные числа и простанства будут разбиваться на пары сопряжённых.
— Нормальность сохраняется
— Сопряжённость — перестановочная с комплексификацией

(Лемма очевидна, если учесть, что любое полиномиальное уравнение, верное в подполе, верно и в самом поле)


Канонический вид:
— В унитарном: находим ОНБ из собственных подпространств, получаем собственные числа на диаонали

— В евклидовом: если все СЧ — вещ. — аналогично. Иначе — добавляем ещё блоки для пар комплексно-сопряжённых.
Матрица перехода всё ещё должна быть ортогональная. Как её найти? Для вещественных собственных чисел — просто собственные векторы. 
Для пар КС разделяем какой-нибудь вектор на пару вещественной и комплексной части и запишем в таком порядке.


\subsection{Самосопряжённый}

(симметричный/эрмитов)

Равносильное определение через скалярное произведение: применить можно как к первому, так и ко второму аргументу, получится то же самое.
И в обратную сторону.

Если A и B САМОсопряжены и перестановочны, то произведение самосопряжено.

Самосопряжён 
<=> нормален + имеет вещественный спектр
<=> существует ОНБ, в котором матрица самосопряжена

Если подпространство инвариантно относительно А, то и ортогональное дополнение — тоже.

В каноническом виде просто пропадут блоки, останутся просто (и в унитарном, и в Евклидовом)


\subsection{Изометричный}

Унитарный/ортогональный

Равносильное определение через скалярное произведение, что если применить к обоим аргументам, скалярное проиведение не изменится.



…
$\Longleftrightarrow$ нормален + собственные числа по модулю = 1
$\Longleftrightarrow$ существует ОНБ, в котором матрица изометрична
$\Longleftrightarrow$ $Q^{-1}$ — изометр.

Если подпространство инвариантно относительно $Q$, то орт. дополнение — тоже.

Каноничечкий вид
— В Евклидовом на диагонали останутся только $± 1$
— В Унтарном в блоках будут $a^2 + b^2 = 1$

Матрица изометрична $\Longleftrightarrow$ её (стобцы $\Longleftrightarrow$ строки) ортонормированы.


\section{Разложения матриц}

$L(D)U$ — нижне-унитреугольная * (Диагональная без нулей на диагонали кроме, возможно, последнего) * верхне-унитреугольная; 
Существует $\Longleftrightarrow$ Все угловые миноры матрицы A, кроме (возможно) $∆_n$ не равны нулю. 

Кстати, здесь $\det L = \det U = 1$, то есть $\prod^k d_i = \Delta_k$, то есть $d_k = \frac{\Delta_k}{\Delta_{k - 1}}$.

Можно найти одновременным Гауссом $A$ и $E$ без замены строк и столбцов. Слева будет $DU$, справа — $L^{-1}$.
Доказывается через преобразования элементарной нижне-унитриугольной матрицей слева, то есть добавляния к $j$-й строке $i$-ую строку с коэффициентом.
(Много таких умножений обеих частей — это и есть метод Гаусса). Пользуемся единственностью, получаем, что нашли то, что нужно.

Если к требованиям левой части добавить сомосопряжённость матрицы, будет $A = LDL^* = U^*DU$. Причём все $d$ вещественные. 
Доказывается через LDU разложения для исходной и сопряжённой матриц (которые равны); $D = \overline{D}$

Положительная/отрицаельная определённость операторов и матриц: 
\begin{enumerate}
    \item Положительно/отрицательно определён, если $\langle \mathcal{A} u, u \rangle$ для всех $\mathbf{u \neq 0}$ больше нуля.
    \item Положительно/отрицательно \textbf{полу}определён, если эта величина всегда больше или равна/меньше или равна нуля.
    (Требование, что для какого-то должна быть равна нулю не предъявляется!)
    \item Не определён, если где-то меньше нуля, где-то — больше.
\end{enumerate}

Это равносильно соотвтствующему утверждению про собственные числа. Доказательство: вспомним, что у самосопряжённого оператора 
собственные числа вещественны, а собственные подпространства ортогональны (по нормальности). 
Разложив и посчитав скалярное произведение разложения любого вектора и убрав перекрёстные слагаемые по ортогональности, получим $\sum_\lambda \lambda \langle u_\lambda, u_\lambda \rangle$




Разложение Холецкого: самосопряжённая положительно определённая ($\Rightarrow$ невырожденная), все угловые миноры — не нули 
$\Longleftrightarrow$ можно в $LDU$ «размазать» $D$, 
разложив на треугольные с положительными элементами на диагонали: $A = LL^* = U^*U$.

Доказательство: по версии LDU для самопряряжённых, $\exists !L, !U, !D, d_k \in \sR: A = LDL^* = U^*DU$.
$A > 0 \Rightarrow \langle U^*DU x, x \rangle = \langle DU x, U x \rangle > 0$, так как $U$ — невырожденный, $Ux$ пробегает всё пространство, то есть
$\forall y \langle D y, y \rangle > 0$, то есть $D$ получился положительно определённым, то есть пололжительные собственные числа, размажем его между $U^*$ и $U$: 
берём $\sqrt{D}$, $(U')* = U^* \sqrt{D} ; U' = \sqrt{D} U$.



$QR$ разложение: для невырожденной можно представить как произведение ортогональной на правую. Или же левой на ортогональную (через разложение транспонирования $A$).
$Q$ находится ортонормированием столбцов исходной. За $R^{-1}$ берём матрицу коэффициентов при ортогонализации (она обьратима, так как на диагонали не нули).

Теорема: можно взять корень из оператора, если он ОПС и с.ч. неотрицаительны. Сделаем это классическим способом через спектральные проекторы. 
Единственность следует из единственнсти спектрального разложения.

Полярное ($QS$ или $SQ$) разложение: на самосопряжённую (H) положительно определённую и изометричную (U).

Док-во: $AA^*$ всегда самосопряжённый, причём положительно определённый, как и $A^*A$.

Нужно взять $\sqrt{A A^*}$ (левый модуль) для получения ортогонального. Далее — через обратную.

Можно также $UH$, получается из $HU$ разложения через взятие обычного от матрицы $A^*$ и $H' = H^*, U' = U^*$, 
в случае невырожденности берём $H = \sqrt{A^* A}$ (правый модуль).




\section{Квадратичные формы}

Кваlратичная — билинейная симметричная (в $\sC$ — полуторалинейная), в которую подставлены одинаковые аргументы: $f(x) = \alpha (x, x)$.

В матричной форме: $x^T A x$.
Ранг формы — ранг её матрицы.

При смене координат $x = Q y$ матрица в новых кородинатах будет $Q^T A Q$.

Если элементы вне диагонали нулевые — канонический вид.

Для формы в каноническом виде пололжительный, отрицательный индексы инерции и количество нулей — количество соответствующих элементов на диагонали.

Сигнатура — это тройка $(\sigma^+(f), \sigma^-(f), \sigma_0(f))$

Нормальный вид — канонический и все элементы $\in \{-1, 0, 1\}$

Приведение к каническому виду ортогональным преобразованием: так как $A$ — симметричная, все с.ч. вещественны и можно, приведя к каноническому виду, получить:

$[V = Q^{-1} = Q^T], A = V^T \Lambda V$, где $V$ ортонормированная.

Метод Лагранжа: Последовательные невырожденные преобразования для диагонализации. 
Если нет ненулувых квадратов, делаем первый шаг:
не трогая остальные переменные, вводим $x_i = y_i + y_j, x_j = y_i - y_j$. 
Получам квадратный член и матрицу с квадратиком на диагонали из $1, 1, 1, -1$.

Если же квадрат есть, разделяем на только этот квадрат с коэффициентом и форму чисто от остальных аргументов.
Для этого выеляем полный квадрат с первым членом, где коэффициенты для остальных берём из перекрёстных членов.
Тогда в качестве новой переменной берём $y_i = \sum_j a_{ij} x_j$. Обратной матрицей преобразования будет, где в i-й строке стоит $a_{ij}$, а остальное — $\delta^i_j$.

Метод Якоби (угловые миноры кроме последнего $\neq 0$): матрца формы самосопряжена, 
так что раскладываем в $A = U^*DU \Rightarrow \Lambda = (U^{-1})^T A U^{-1}$, причём будет состоять из отношений миноров.
Тогда берём $Q = U^{-1}$.
Существует единственное такое верхнее унитреугольное преобразование, причём его можно найти через $A_{k -1} q_i = -b_i$, где $A_i$ — угловые матрицы $A$, $q_i$ столбцы $q$, $b_i$ — верхние части столбцов $A$.

Для n = 2 доказываем русками через разложение. Далее — по индукции через деление матрицы на 4 части.

Note: если ранг $n - 1$, а не $n$, проведём сначала невырожденное преобразование матрицей перестановки, получив все миноры кроме последнего не нули.



Критерий инерции квадратичный форм: любое невырожденное преобразование к каноническому виду, даёт одинаковую сигнатуру.

Докажем от противного. Во-первых, ранг не меняется при невырожденных преобразованиях. 
Запишем с два приведения формы к КВ с разным количеством пололжительных и отрицательных (но $\sigma^+ + \sigma^- = \rg f$, то есть нулевых одинаково).

НУО, $p < s$. Для любого $y, z$ системы $Q_1^{-1} \mathbb{x} = y$ и $Q_2^{-1} \mathbb{x} = z$ имеют единственное решение в силу невырожденности.

Сделаем $y_0$ — вектор из нулей в первых $p$ позициях, в остальных — что угодно. И $z_0$ — с нулями в последних $n - s$, а в первых $s$ — что угодно.

Сделаем однородную систему из $p + n - s < n$ уравнений, взяв первые $p$ уравнений из $Q_1^{-1} \mathbb{x} = y$ 
и последние $s$ из $Q_2^{-1} \mathbb{x} = z$. Тогда будет нетривиальное решение новой системы $x^*$.
Обозначим $y^* = Q_1^{-1} \mathbb{x^*}, z^* = Q_2^{-1} \mathbb{x^*}$. С одной стороны, $y^* \neq 0 \neq z^*$, так как $x^* \neq 0$.
С другой — первые $p$ и последние $s$ — нули, так как мы брали нужные уравнения из соответствующей системы.
Тогда остальные элементы — не только нули.

Но тогда перейдём к координатам в обоих $x$, получив, что $f(x^*) = g(y^*) > 0$ и $= h(z^*) < 0$ одновременно. 

Знакоопределённость формы — определяется как у матрицы.

Критерий Сильвестра: если все угловые миноры ненулевые, то: 
если все положительные, она положительно определённая, если чередуются начиная с отрицательного — отрицательно определённая,
если всё это для предыдущих и последний минор равно нулю, то полуопределённая с соответствующим знаком. Иначе — НЕопределённая.

ПВП к каноническому виду: выделяем квадратичную форму, избавляемся от перекрёстных членов ортогональным преобразованием, заменяем координаты (меняются и линейные члены тоже).
Затем делаем параллельный перенос, получаем 

\end{document}
