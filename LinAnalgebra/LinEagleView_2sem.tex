\documentclass[12pt, a4paper]{article}

\input{../LatexGloves/latex_math_header.tex}


\title{Сжатый конспект по линейной алгебре \\(2-й семестр)} 

\author{
  \vova
  \and
  Кучерук Елена Аркадьевна (лектор)
}

\date{\today}



\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage


\section{Введение}

    Конспект старается быть максимальнго краткой выжимкой из того, 
    что нужно знать для успешной сдачи экзамена по Линейной Алгебре во втором семестре.

    Если кто-то сдаёт часть про линейные операторы и говтов по них написать, welcome.

\section{Сопряжённое пространство}

$V^*$ пространство линейных форм над $V$.

Вычисление формы на коордлинатном столбце $f(x) = \mathrm{x}^j a_j$, 
где строка $a_j$ размера n изоморфно сопоставляется форме.

— Координатные функции относительно базиса, $\omega^i(e_j) = \delta^i_j$.

Они базис $V^*$, так как их как раз $n$, а породить любую $f$ можно, предъявив коэффициенты $a_j$.

По $e$ мы научились находить сопряжённый базис, теперь научимся в обратную сторону 
находить по базису $V*$ такой базис $V$, чтобы исходный был к нему сопряжён:
возьмём любую сопряжённую пару $e, \omega$ 
и через это получим $\omega' → (e', \omega')$

Если назвать $S = T_{\omega → \omega'}^T$, утверждается, 
что можем получить $e'$ так: $T_{e → e'} = S^{-1}$

Чтобы доказать — проверим, что $\omega'$ — координатные функции $e'$.
То есть что координаты преобразуются правильно: $x' = S x$.

Элементы $V^*$ КОвариантные, так как преобразуются (получение новых из старых) 
с матрицей $T_{e → e'}$, 
а элементы $V$ — контравариантные, так как с матрицей $S = T^{-1}$

Доказывам, что можно получить изоморфизм 

\begin{equation}
    \varphi: V → (V^*)^*, x → "x" \quad \mathrm{where} "x"(f) = f(x)
\end{equation}

Кстати, $\varphi \in \Aut (V → (V^*)^*)$.

Линйеность $\varphi$ очевидна, для биективности в силу линейности 
достаточно проверить, что базис переходиь в базис (что $\rg \varphi = n$).
Действительно, $"e_j"$ — координатные функции базиса координатных функций, 
так как, $"e_j"(f) = f(e_j) = (a_f)_j$.

Отличие от $V \leftrightarrow V^*$ — в том, что теперь оно не зависит от выбора базиса.

— Умеем считать сопряжённый базис через обратную матрицу 
и матрицы проекторов через сопряжённый базис.



\section{Тензоры}

\subsection{Два определения, смена базиса}

Это функция $V^p × (V^*)^q → \mathcal{K}$.

То, что «из векторов» — ковариантное, «из форм» — контрвариантное.

$T_{(p; q)}$ — линейное пространство размерности $n^(p + q)$

За счёт линейности при вычислении на наборе векторов, разложенных по базису,
можно вынести $p + q$ сумм с координатами, остаются значения тензора 
на разных размещениях базиса, их мы назовём компонентами относительно базисов $e, \omega$.

$\alpha^{j_1, …, j_q}_{i_1, …, i_p}$
Сверху пишется q «контравариантных индекса» — из форм.
Снизу — p ковариантные индексы — из векторов.

Это можно записать в $p + q$-мерную матрицу.

Смена базиса. Выразив старые координаты через новые 
($\xi^i = t^i_k {\xi'}^k, \eta_j = s^m_j {\eta'}_m$), 
подставим в формулу вычисления на наборе векторов, 
сгруппируем $t, s, \alpha$ скажем, что это новый компонент, 
а новые координаты как раз останутся.

Другое определение тензора: это многомерная матрица, 
в которой выделены «ковариантные» и «контравариантные» координаты 
и которая пересчитывается при смене базиса по той же формуле, что и выше.

Определения эквивалентны.

\subsection{Тензорное произведение, свёртка, транспонирование}

Тензорное произведение: вводим через второе определение 
(многомерная матрица), проверяем вариантность.

Говорим, что в терминах линейных форм мы берём 
каждую от своей части координат и перемножаем результаты.

Базис вводим базис $T_{(p; q)}$ 
из $n^{p + q}$ тензорных произведений всех размещений $e_i, \omega_j$,
помня, что 

\begin{gather*}
    \omega_j : (V)^1 → \mathcal{K} \\
    e_i \cong "e_i" : (V^*)^1 → \mathcal{K}
\end{gather*}

Доказываем, что это базис, так как количество $n^{p + q}$ 
и порождающее: за коэффициенты для порождения берём 
компоненты относительно базиса, доказываем через формулу вычисления на наборе векторов.

Заметим, что матрица тензора из базиса будет содержать одну единицу 
на соответствующих индексах и все остальные нули.

Вводим свёртку как матрицу, доказываем, что это тензор, помня, что 
$t_{\tilde{\kappa}}^{\kappa_{2}} s_{\kappa_{1}}^{\tilde{\kappa}} = \delta_{\kappa_{1}}^{\kappa_{2}}$ 
и оставляя в сумме только слагаемые, где $\kappa_{1}=\kappa_{2}=\kappa$.

Транспонирование: $\beta = \sigma(\alpha), \beta_{j_{1} \cdots j_{p}}^{i_{1} \cdots i_{q}}=\alpha_{j_{\sigma_{1}} \cdots j_{\sigma_{p}}}^{i_{1} \cdots i_{q}}$.

То есть набор индексов $\alpha$ переходит в индексы $\beta$ 
под действием обратной к $\sigma$ перестановки.

Доказываем, что тензор 
(достаточно доказать про транспозиции, 
так как перестановка раскладывается на композицию транспозиций) 

Заметим, что в терминах функций мы переставлем аргументы, тоже с обратной перестановкой.

Транспонирование — изоморфизм, ассоциативно, но коммутаитвно (как и группа перестановок).

Если при любом транспонировании тензора он не меняется, он симметричен, 
если умножается на $(-1)^{\varepsilon(\sigma)}$, то кососимметричен.

Кососимметричен $\Leftrightarrow$ равен нулю при повторяющихся аргументах.

\subsection{Симметрирование, альтенирование}

Оба перестановочны относительно перестановки, 
причём для симметрирования получается просто симметрирование,
а для альтенирования — оно умножить на знак перестановки.
(доказывается, используя, что если все перестановки $S_n$, по которым мы суммируем,
пропустить через одну перестановку, получим тоже все перестановки, но в другом порядке — таблица Кэли, иначе не группа)

$\alpha$ симметричен $\Leftrightarrow \alpha = \Sim \alpha$.
$\alpha$ КОСОсимметричен $\Leftrightarrow \alpha = \Alt \alpha$.

Обе идемпотентны, причём $\Sim \Alt \alpha = 0$ 
(то есть симметрирование любого кососимметричного — ноль, ведь можно подставить кососимметричный
$\beta = \Alt \beta$, тогда $\Sim \beta = \Sim \Alt \beta = 0$).

Доказывается, заметив, что сумма чётностей по всем перестановкам — это ноль, 
так как это определитель матрицы со всеми единицами.

Заметим, что пересечение подпространств симметричных и антисимметричных тензоров — тривиально.
Более того, если транспозиция одна (по двум индексам), 
то пространство всех тензоров заданного типа раскладвыаются в дизъюнктную сумму симметричных и антисимметричных (по этим индексам), 
где $\alpha = \Sim \alpha + \Alt \alpha$

\subsection{p-формы}

$p$-формы — антисимметричные ковариантные тензоры, Если от одного аргумента, отождествляют с $V^*$.

Внешнее произведение: $f \land g = \frac{(p_f + p_g)!}{p_f! p_g!} \Alt (f \otimes g)$.

Есть свойства, можно через них раскрывать скобки.

1. $f \wedge g=(-1)^{p_{1} p_{2}} g \wedge f$.
2. $(f+g) \wedge h=f \wedge h+g \wedge h$ и $f \wedge(g+h)=f \wedge g+f \wedge h$.
3. $\lambda \cdot(f \wedge g)=(\lambda f) \wedge g=f \wedge(\lambda g)$.
4. $\mathbb{D}_{\Lambda^{p_{1}} V^{*}} \wedge g=f \wedge \mathbb{\mathbb { D }}_{\Lambda^{p_{2}} V^{*}}=\mathbb{D}_{\Lambda^{p_{1}+p_{2}} V^{*}}$.
5. $(f \wedge g) \wedge h=f \wedge(g \wedge h)=\frac{\left(p_{1}+p_{2}+p_{3}\right) !}{p_{1} ! p_{2} ! p_{3} !} \operatorname{Alt}(f \otimes g \otimes h)$.

2, 3, 4 — очевидно.

1 — записываем по определению, сопоставляем у сумм слагаемые, 
смотрим на количество инверсий между ними, оно как раз $p_f p_g$.

5 — по определению, доказываем, что $\Alt(\Alt(f \otimes g) \otimes h) = \Alt(f \otimes \operatorname{Alt}(g \otimes h)) = \Alt(f \otimes g \otimes h)$.
По линейности заносим второе тензорное произведение под внутреннюю сумму, 
потом создаём перестановку, работающую на всех трёх наборах индексов, но переставляющую только первые два как $\sigma$,
по линейности альтенирования заносим его под сумму, замечаем альтенирование от перестановки, сокращаем $(-1)$, конец.

По индукции можно обобщить формулу для внешнего произведения на несколько векторов.


Есть базис пространства антисимметричных $p$-форм (антисимметричных тензоров) 
размера $\begin{pmatrix} n \\ p \end{pmatrix}$ из врешних произведений 
упорядоченных комбинаций кординатных функций. 
Координаты в нём называют существенными, они численно совпадают 
с координатой для того же набора в пространстве всех тензоров.


Можно вычислить значение внешнего произведения 1-форм на наборе векторов через определитель 
матрицы применения каждой функции к каждому вектору.

Также можно найти координаты внешнего произведения в базисе внешних произведений, 
если знаем разложение самих функций по базису пространства линейных форм.

Комбинируя, можно через сумму произведений двух соответствующих опредеителей 
вычислить функцию, заданную произведением $1$-форм, заданных координатами, 
на наборе векторов, заданных координатами.


\section{Евклидовы пространства}

\subsection{Аксиомы, КБШ}

Скалярное (линейные пространства над вещественными числами) — функция от двух векторов: 
симметричность, линейность по первому ($\Rightarrow$ каждому) аргументу, 
положительная определённость.

Псевдоскалярное (линейные пространства над комплексными числами): 
то же самое, только симметричность — эрмитова и по второму аргменту становится 
«эрмитова» однородность, хотя и нормальная аддитивность.

Евклидова норма — корень из скалярного квадрата.

КБШ: $| \langle x, y \rangle | \leqslant ||x|| ||y||$, причём равенство только при линейной зависимости.
Доказываем так: берём положительное $\langle \alpha x + \beta y, \alpha x + \beta y \rangle$, раскрываем, подставляем
$\alpha = <y, y>, \beta = -<x, y>$, выносим $||y||$, получаем, что искомое положительно.
Из равенства в КБШ сдедует зависимость, так как мы берём вот эти альфа и бета, получаем скалярный квадрат ноль.
Из зависимости следует равенство: берём $\alpha x + \beta y = 0$ по определению л.з., 
рассматриваем $\langle\alpha x+\beta y, x\rangle=0; \langle\alpha x+\beta y, y\rangle=0$, раскрываем, перемножаем равенства, конец.

Проверка свойств норм для Евклидовой нормы:
Положительная определённость, однородность — очевидно. 
Нер-во треугольника: доказываем про квадраты норм, раскрывая $||x + y||^2$, замечая сумму сопряжённых, применяя КБШ и получая полный квадрат.

Ортогональая система — линейно независима. Доказвается, скалярно умножая нулевую линейную комибнацию на базисный вектор, 
по ортогональности остаётся толко его компонент. 

\subsection{Грам-Шмидт, примеры}

Грам-Шмидт: систему векторов можно заменить на ортогональную систему не большего размера с сохранением линейной оболочки.
Процессируя очередной вектор, будем вычитать линейную комбинацию предыдущих, уже ортогональных. Так, чтобы новый стал ортогонален каждому.
Если на каком-то шаге получится ноль, выкинем его.

Ортонормированную систему можно дополнить до ОНБ.

Примеры: коэффициенты Фурье, полиномы Лежандра.

Формула Родрига: $\tilde{e_k} = \lambda_k \left( (x^2 - 1)^k \right)^(k)$.

Доказываем, что $\tilde{e_k} \perp x^m \forall m < k$. Берём интегралл, много раз интегрируя по частям, уменьшая степень $x^m$ и уменьшая количество дифференцирований у $\tilde{e_k}$
каждый раз подстановка обнуляется, так как \textit{Если полином имеет корень кратности $k$, этот корень — кратности $k - 1$ у производной}.

Общая формула Родрига (хотя почему общая?…). Если взять $\lambda_k = \frac{1}{2^k k!}$, то $\tilde{e_k}(1) = 1$. 
Для доказательства вычислим $\tilde{e_k}(1)$ по формуле Лейбница для произведения $(x - 1)^k (x + 1)^k$, где слагаемые для $i != k$ обнуляются.

Квадрат нормы полиномов будет $\frac{2}{2k + 1}$ (опять интегрируеим по частям, уменьшая степень у одного и поднимая у другого).

Полиномы Чёбышева. Скалярное произведение — с весом $\frac{1}{\sqrt{1 - x^2}}$, получаем $T_n = \cos(n \cos^{-1}(x))$.
Доказываем, что это полиномы по индукции, что $T_{n + 1} + T_{n - 1} = 2x T_n$.

Полиномы Эрмита. Скалярное произведение — от нуля до $+\infty$ с весом $e^{-x^2}$.
$H_n = e^{x^2} \left( e^{-x^2} \right)^(n)$.


\subsection{Матрица Грама, её определитель}

Скалярное произведение в кооринатах: через матрицу Грама для базиса, $\left\langle x, y \right\rangle = x^T \Gamma \overline{y}$.
Для ортонормированного — матрица единичная.

Матрица Грама сомосопряжена.

Теорема об определителе матрицы Грама: если система зависима, он равен нулю, 
иначе — произведению скалярных квадратов векторов, получающихся ортогонализацией Грама-Шмидта.

Доказывается, вычитанием в определителе $g(…, a_i, …)$ соответствующих линейных комбинаций одновременно из строк и столбцов 
$\rightsquigarrow$ на каждом шаге все $a_i$ в матрице заменяются на $b_i$. Получаем определитель ортогональной системы, то есть $| \diag (b_i) |$.

Можем посчитать норму ортогонализации нового вектора через отношение матриц нового и старого определителя, если исходная система независима.

Объём параллелепипеда — корень из определителя Грама.

Можно вычислить матрицу Грама системы так: $G(a_1, …, a_i) = A^T \Gamma \overline{A}$. Для ОНБ, понятно, $\Gamma$ убирается.

Причём, если количество векторов равно размерности пространства, а $\Gamma = E$, объём — это просто определитель матрицы координат.

Объём под действием оператора изменяется в $\det \mathcal{B}$ раз (как определитель системы векторов при применении оператора). 
Например, при повороте объём сохраняется, а при гомотетии растёт в $\lambda$ раз.

Матрица Грама базиса положительно определённая, её угловые миноры больше нуля.
Она преобразуется при смене базиса: $\Gamma' = T^T \Gamma \overline{T}$. 
(Доказывается через смену координат в формуле для скалярного произведения и подстановку $x' = e_i, y' = e_j'$, ведь мы уже получили, 
что скалярное произведение элементов считается через эту матрицу, а значит, и для базисных векторов это тоже верно).

\subsection{Изометрическая матрица}

Изометрическая матрица: обратна сопряжению.

Свойства: 

\begin{enumerate}
    \item Изометричность равносильна ортонормированности столбцов, как и строк ($\Gamma = E$). 
    Доказыввается через $Q^T \overline{Q} = E$, что соответствует $\langle q_i, q_j \rangle = \delta^i_j$
    \item $Q$ — изометрично $\Leftrightarrow$ $Q^{-1}$ — изометрично 
    \item Произведение изометричных изометрично
    \item $| \det Q | = 1$
    \item Матрица перехода между ОНБ — изометрична (по формуле для $\Gamma'$).
\end{enumerate} 

\subsection{Ортогональное дополнения, расстояния}

$L^{\perp}$ — ортогональное дополнение $L$ — мн-во векторов, ортогональным всем векторам $L$.

Это линейное подпространство, $L \cap L^{\perp} = \{\mathbb{0}\}$, причём $L \oplus L^{\perp} = V$. 
(Для док-ва дополним онб $L$ до онб $V$. Подпространство, натянутое на добавленные векторы является прямым дополнением $L$, 
причём в сумме — онб, то есть любой вектор из дополнения ортогонален $L$, то есть полученное дополнение содержится в $L^{\perp}$,
причём $\dim L^{\perp} \leqslant \dim V - \dim L$, так как иначе бы их пересечение было нетривиально)

${L^\perp}^\perp = L$ — доказываем подмножественность и равенство размерностей.

$(L_1 + L_2)^\perp = L_1^\perp \cap L_2\perp; (L_1 \cap L_2)^\perp = L_1^\perp + L_2\perp$. 
Доказываем прямое и обратное включение, подставляя нули в качестве некоторых векторов.
Второе следует из первого.

Единственность представления вектора как сумму составляющих из $L$ и $L^\perp$: $x = y + z$. 
(Едиственность и так известна из дизъюнктности, но здесь есть хороший способ поиска).
Найдём разложение составляющей из $L$ по базису $L$. Составим СНЛУ, что $\langle x, l_i \rangle = \langle y, l_i \rangle$,
раскрыв это по разложению с кроэффициентами $c_i$ и линейности.
Получим СЛНУ с единственным решением за счёт $det G \neq 0$:

\begin{equation}
    G(l_1, …, l_{\dim L})^T \mathbb{c} = \langle \mathbb{x, l} \rangle
\end{equation}

Теорема Пифагора: для перпендикулярных векторов квадрат суммы — это сумма квадратов, так как смешанные слагаемые обнуляются.
Можно также обобщить на n перпендикулярных векторов.

Теорема о наилучшем приближении: ортогональная проекция — самый близкий элемент $L$ к исходному вектору. (Из Пифагора)

Расстояния между точкой и линейным пространством, точкой и многообразием, двумя многообразиями.

$dist^2(x, L) = \frac{g(…, x)}{g(…)}$, так как при ортогонализации в числителе $x$ превратится в компоненту относительно $L^{\perp}$

Для многообразия $\rho(x, [P = x_0 + L]) = \rho(x - x_0, L)$, доказывается через резложение $x - x_0 = y + z$ и примерение теоремы Пифагора.

$\rho([P_1 = x_1 + L_1], [P_2 = x_2 + L_2]) = \rho(x_1 - x_2, L_1 + L_2)$, так как 

\begin{equation}
    \min_{\substack{l_{1} \in L_{1} \\ l_{2} \in L_{2}}} \left\| x_1 - x_2 + l_1 - l_2\right\| = 
    \min_{l \in L_{1}+L_{2}} \left\|x_1 - x_2 + l\right\|
\end{equation}

Пространство можно разложить в прямую сумму попорно ортогональных подпространств.
Если они все размерности 1, можно найти коэффициенты по Формуде Фурье: $x_i = \frac{\langle x, e_i \rangle}{\langle e_i, e_i \rangle}$ (просто скалярно домножили разложение в ОБ на $e_i$).

Тождество Парсеваля: в ортогоналном базисе $||x||^2 = \sum |x_i| ||e_i||^2$ (по теореме Пифагора)
(Для бесконечномерных будет только неравенство БесселяЖ будет знак $\leqslant$)

Мы также можем строить проекторы на одномерные ортогональные пространства через склярные произведения с элементами базиса (коэффициенты Фурье).

\subsection{Изометрия $V$ и $V^{*}$}

Пространства изометричны — существует изоморфизм с сохранением скалярного произведения.

На любых евкл/унит прострснствах одной размерности можно ввести изометрию: 
сопоставляем векторы с одинаковыми коэффициентами в разложениях фиксированных \textbf{ОНБ}. 
Понятно, что такая изометрия зависит от выбора базисов.

Теорема Рисса. Можно провести естественный изоморфизм между $V$ и $V^*$:

$x → \langle ., x \rangle$, понятно, что оно будет линейно. Докажем, что биекция, предъявив обратное сопоставление:

Зафиксируем ОН базис (хотя от его выбора результат не зависит). Хотим найти такой $x$ по $f$, что $f = \langle \cdot, x \rangle$.
В частности, это верно и для базисов. $f(e_i) = \langle e_i, x \rangle = x_i$.
То есть мы получили, что $x$ может быть только таким. Проверим, подходит ($\Gamma = E$).

В унитарном пространстве будут проблемы с линейностью соответствия (но не полученной формы, с этим всё нормально, так как первый аргумент).

Можно ввести через $\varphi^{-1}$ скалярное произведение на $V^*$, чтобы изоморфизм стал изометрией.


\subsection{Метрические тензоры, взаимные базисы}

(Здесь работаем только с $\sR$)

Метрический (дважды) КОвариантный — с матрицей $\Gamma$, КОНТРвариантный — с матрицей $\Gamma^{-1}$.
Проверим, вариантность действительно такая по формуле $\Gamma'$.

Эти тензоры 

\begin{itemize}
    \item Симметричны
    \item Представляют собой обратный матрицы, так что свёртка, соответствующая произведению матриц, даёт $\delta^i_j$. Они симметричны, так что можно менять индексы свёртки и порядок тензоров как угодно.
    \item $\langle x, y \rangle = g_{ij} x^i y^j$.
\end{itemize}

Базисы взаимны, если $\langle e_i, e^j \rangle = \delta^i_j$.
(ОНБ, например, ортогонален сам себе).

Для любого базиса существует единственный взаимный ему. 
Для доказательства предъявим матрицу перехода к взаимному, доказав, что её можно найти единственным образом.
Распишем по определению, домножим выражение одного из векторов нового базиса скалярно на какой-нибудь вектор исходного.
Получим, что необходимо и достаточно, чтобы строка матрицы $T$ и Грама давала $\delta^i_j$.

Можно то же самое оформить проще: потребовать, чтобы матрица скалярных произведений одного и другого бызиса была единичной:

\begin{equation}
    \langle e_i, e_j \rangle (e_{…})^T \Gamma (e^{…}) = E = E \Gamma T = E
\end{equation}

Одинаково ориентированные — матрица перехода имеет положительный определитель. (Быть одинаково ориентированными — отношение эквивалентности).

Взаимные как раз ориентированы одинаково.

Базис, полеченный из сопряжённого через теорему Риса — взаимен исходному. (Очевидно по определению и Т. Риса)

Форумлы Гибса: разложение вектора по базису находится взаимному через скалярное произведение. (Запишем разложение по коорлинатам в исходном базисе)
NOTE: в Фурье был ОНБ, который взаимен сам себе, здесь более общий случай.

Координаты во взаимном базисе — коварианты. 
$x_j = \langle x, e_j \rangle$. А значит, $\langle x, e_j \rangle$ — $j$-я координатная фунция относительно базиса $e^{…}$, она сопоставлена по теореме Рисса $e_j$.
$\langle x, e_j \rangle$ — базис, сопряжённый $e^j$. 
Но мы знаем, что теорема Риса сопоставляет $e^j \leftrightarrow w^j$. 
А теорема Рисса преобразует базис в такой базис, что 

Итого: координаты вектора во взаимном равны координатнам соответвующей функции в базисе $w^j$, а они ковариантны.

Опускание индексов: умеем считать скалярное произведение через метрический тензор, тогда определим опеации опускания и поднятия.

Если мы переходим между ОНБ, то матрица перехода ортогональная, то есть $S = T^{-1} = T^T$, то есть в разложении можем писать вместо $s^i_j$ $t^j_i$. Правдо, правило Эйнштейна не работает.

Евклидов тензор $\Leftrightarrow$ при свертке с метрическим меняется только порядок записи индексов, а значения тензора не меняются

\section{Операторы в Евкливых пространствах}

\subsection{Сопряжённый}

Сопряжение оператора: обычно сопоставляется $(U → V) → (V^* → U^*)$ через композицию.

Но по теореме Рисса скажем, что как будто сопряжённый — это $V → V$.

И это эквивалентно тому, что $\forall x, y: \langle \mathcal{A} x, y \rangle = \langle x,  \mathcal{A}^* y \rangle$


Матрица $\overline{\Gamma^{-1}} A^* \overline{\Gamma}$ (доказывается через подсчёт обеих скалярных произведений и подстановку базисных векторов), 
в онб — просто $A^*$
Сопряжение — взаимообратно (свопаем обе части).

Отнсительно компоиции — как транспонирование. (Для доказательства перекидываем внешний, а потом и внутренний оператор направо)

Аддитивность, псевдоОднородность.
Перестановочность относительно $(.)^{-1}$ (если исходный обратим). Доказывается через предъявление.

Ядро оператора и образ сопряжённого — ортогональные дополнения друг друга, как и образ оператора и ядро сопряжённого.
Доказывавем, что из ядра $\Rightarrow$ ортогонален любому из образа сопряжённого. Добавляя равенство размерностей, получаем равенство. 

Второе следует за счёт взаимообратности сопряжения.

Характеристический многочлен равен нулю на $t$ $\Leftrightarrow$ хар. многочлен сопряжённого равен нулю на $\overline{t}$.

Докажем для ОНБ, так как от базиса не зависит. Сопряжём многочлен и воспользуемся, что получившаяся $\overline{A}^T$ — это матрица сопряжённого в ОНБ.

Итого: Собственные числа — разбиваются на пары сопряжений друг друга.

Для не соответствующих — собственные векторы ортогональны.

Первое: При применении $A$ к первому аргументу увеличивается в $\lambda$ раз, при применении сопряжённого ко второму — в $\overline{\mu}$ раз.
Но они равны, что возможно только при равенстве нулю скалярного произведения, если $\lambda \neq \overline{\mu}$

Если подпространство инвариантно относительно A, то его ортогональное дополнение — относительно A*.
По условию если применить оператор к вектору из пространства и умножить на вектор из дополнения, получится ноль, но с другой стороны по сопряжённости получим, что $A^* y \in {L^\perp}$


\subsection{Нормальный}

$\Longleftrightarrow$ Перестановочен с сопряжённым 
$\Longleftrightarrow$ $\langle A x, A y \rangle = \langle A^* x, A^* y \rangle$ 
$\Longleftrightarrow$ В некотором базисе матрицы перестановочны (операторы равны <=> существует базис, в котором их матрицы равны)
$\Longleftrightarrow$ ОПС + собственные пространства ортогональны 
$\Longleftrightarrow$ Существует какой-нибудь ОНБ, что матрица имеет понятно какой блочно-диагональный вид


Не перестанет быть нормальным, если вычесть сколько-то id.

Для нормального для соответствующих собственных чисел ($\lambda, \overline{\lambda}$) собственные пространства у $A$ и $A^*$ совпадают: $\mathcal{B} u = 0 \Leftrightarrow \langle B^* u, B^* u \rangle = 0$



У нормального оператора ядро и образ — ортогональные дополнения друг друга 
(если удалось получить собственные числа из того же поля, то потому, что это собственное подпространство нуля и все остальные).
Но вообще докажем это через $\Ker A = \Ker A^*$. Это правда, проверим по определению.

Причём ядро не расширяется при возведении в степень.
Докажем так: $\langle A^2 x, A^2 x \rangle = … \langle AA* x, AA* x \rangle$, это всё равно что $Ax \in \Ker A^* = \Ker A$, но это дизъюнктно с $\Img A$, то есть получили, что $Ax = 0$, то есть $x \in \Ker A$

Note: Так как у нормального $\Ker A = \Ker A^*$, инвариантность отностельно $A$ и$A^*$ равносильна.

Канонический вид в унитарном: нормальный $\Leftrightarrow$ существует ОНБ из собственных векторов, в котором диагональный.
Влево очевидно.
Вправо: будем доказывать по индукции по размерности пространства, откучывая по одному собственному вектору и говорить, 
что собственное подпространство инвариантно относительно исходжного и сопряджённого операторов, а значит, ортогоональное дополнение — тоже. 
Значит, сужение будет действовать из дополнения в дополнения — это нормальный оператор, причём для размерности на 1 меньше исходной, про которую мы всё доказали.

Лемма о комплексификации (оператора):

Вводим скалярное произведение как $\langle x_1 + i y_1, x_2 + i y_2 \rangle = \langle x_1, x_2 \rangle + \langle y_1, y_2 \rangle + i \left(-\langle x_1, y_2 \rangle + \langle y_1, x_2 \rangle\right)$.
В общем, как произведение, только наоборот. Проверим аксиомы.

В нашем случае $\overline{\langle z_1, z_2 \rangle} = \langle \overline{z_1}, \overline{z_2} \rangle$.


\begin{enumerate}
    \item Вещественные собственные числа сохранются, собственные подпстранства будут комплексификацией соответствующих
    \item Комлексные собственные числа и простанства будут разбиваться на пары сопряжённых
    \item Сопряжённость — перестановочная с комплексификацией
    \item Нормальность сохраняется
\end{enumerate}

\begin{enumerate}
    \item Что сч сохраняются, доказывали. Про подпространство доказываем оба включения, говоря, что увеличиваются во сколько надо раз.
    \item Докажем, что, если нашли пару $(\lambda, z)$, то будет и пара $(\overline{\lambda}, \overline{z})$. 
    Причём, если собственные векторы получились ортогональны, то нормы комплексной и вещественной частей вектора равны, а части векторов — перпендикулярны.
    \item Берём ОНБ в вещественном, получаем ОНБ в комплексифиции, а в нём будет сопряжёная матрица
    \item Следует из предыдущего.
\end{enumerate}

Канонический вид:
— В унитарном: находим ОНБ из собственных подпространств, получаем собственные числа на диаонали

— В евклидовом: если все СЧ — вещ. — аналогично. Иначе — добавляем ещё блоки для пар комплексно-сопряжённых.
Матрица перехода всё ещё должна быть ортогональная. Как её найти? Для вещественных собственных чисел — просто собственные векторы. 
Для пар КС разделяем какой-нибудь вектор на пару вещественной и комплексной части и запишем в таком порядке.

Доказательство для евклидового:

Разбиваем комплексификацию в дизхюнктную сумма попарно ортогональных собственных пространств: сначала идёт комплексификация вещественных, потом пары сопряжённых.

Потом посмотрим на сопряжённые пары комплексных и скажем, что в качестве базиса достаточно взять комплексную линейную оболочку $x, y$, которая является комплкесификацией вещественной линейной оболочки.

Тогда получим ОНБ исходного пространства, в нём будет такая же матрица, как и в комплексификации.

Тогда мы знаем, как применить $A_\sC$ к $x = \frac{z + \overline{z}}{2}$ и $y$.
$A\sC(x) = \alpha x - \beta y$, то есть у нас получилась дизъюнктная сумма инвариантных, получаем блочную матрицу.


\subsection{Самосопряжённый}

(симметричный/эрмитов)

Равносильное определение через скалярное произведение: применить можно как к первому, так и ко второму аргументу, получится то же самое.
И в обратную сторону.

Если A и B САМОсопряжены и перестановочны, то произведение самосопряжено.
Можно также складывать самосопряжённые, умножать на ВЕЩЕСТВЕННЫЙ скаляр, обращать.


Если подпространство инвариантно относительно А, то и ортогональное дополнение — тоже.

Самосопряжён
<=> нормален + имеет вещественный спектр (для этого приведём к каноническому виду и скажем про самосопряжённость)
<=> существует ОНБ, в котором матрица самосопряжена






В каноническом виде просто пропадут блоки, останутся просто сч (и в унитарном, и в Евклидовом)


\subsection{Изометричный}

Унитарный/ортогональный

Равносильное определение через скалярное произведение, что если применить к обоим аргументам, скалярное проиведение не изменится.



…
$\Longleftrightarrow$ нормален + собственные числа по модулю = 1
$\Longleftrightarrow$ существует ОНБ, в котором матрица изометрична
$\Longleftrightarrow$ $Q^{-1}$ — изометр.

Если подпространство инвариантно относительно $Q$, то орт. дополнение — тоже.

Каноничечкий вид
— В Евклидовом на диагонали останутся только $± 1$
— В Унтарном в блоках будут $a^2 + b^2 = 1$

Матрица изометрична $\Longleftrightarrow$ её (стобцы $\Longleftrightarrow$ строки) ортонормированы.

Изометричный $\Longleftrightarrow$ переводит ОНБ в ОНБ.
Вправо — очевидно, влево — раскрываем скалярное произведение.


\section{Разложения матриц}

$L(D)U$ — нижне-унитреугольная * (Диагональная без нулей на диагонали кроме, возможно, последнего) * верхне-унитреугольная; 
Существует $\Longleftrightarrow$ Все угловые миноры матрицы A, кроме (возможно) $∆_n$ не равны нулю. 

Кстати, здесь $\det L = \det U = 1$, то есть $\prod^k d_i = \Delta_k$, то есть $d_k = \frac{\Delta_k}{\Delta_{k - 1}}$.

Доказываем по индукции, помня, что на очередной угол результата влияют только угловые части матриц: $A_k = L_k D_k R_k$.

Можно найти одновременным Гауссом $A$ и $E$ без замены строк и столбцов. Слева будет $DU$, справа — $L^{-1}$.
Доказывается через преобразования элементарной нижне-унитриугольной матрицей слева, то есть добавляния к $j$-й строке $i$-ую строку с коэффициентом.
(Много таких умножений обеих частей — это и есть метод Гаусса). Пользуемся единственностью, получаем, что нашли то, что нужно.

Если к требованиям левой части добавить сомосопряжённость матрицы, будет $A = LDL^* = U^*DU$. Причём все $d$ вещественные. 
Доказывается через LDU разложения для исходной и сопряжённой матриц (которые равны); $D = \overline{D}$

Положительная/отрицаельная определённость операторов и матриц: 
\begin{enumerate}
    \item Положительно/отрицательно определён, если $\langle \mathcal{A} u, u \rangle$ для всех $\mathbf{u \neq 0}$ больше нуля.
    \item Положительно/отрицательно \textbf{полу}определён, если эта величина всегда больше или равна/меньше или равна нуля.
    (Требование, что для какого-то должна быть равна нулю не предъявляется!)
    \item Не определён, если где-то меньше нуля, где-то — больше.
\end{enumerate}

Это равносильно соотвтствующему утверждению про собственные числа. Доказательство: вспомним, что у самосопряжённого оператора 
собственные числа вещественны, а собственные подпространства ортогональны (по нормальности). 
Разложив и посчитав скалярное произведение разложения любого вектора и убрав перекрёстные слагаемые по ортогональности, получим $\sum_\lambda \lambda \langle u_\lambda, u_\lambda \rangle$




Разложение Холецкого: самосопряжённая положительно определённая ($\Rightarrow$ невырожденная), все угловые миноры — не нули 
$\Longleftrightarrow$ можно в $LDU$ «размазать» $D$, 
разложив на треугольные с положительными элементами на диагонали: $A = LL^* = U^*U$.

Доказательство: по версии LDU для самопряряжённых, $\exists !L, !U, !D, d_k \in \sR: A = LDL^* = U^*DU$.
$A > 0 \Rightarrow \langle U^*DU x, x \rangle = \langle DU x, U x \rangle > 0$, так как $U$ — невырожденный, $Ux$ пробегает всё пространство, то есть
$\forall y \langle D y, y \rangle > 0$, то есть $D$ получился положительно определённым, то есть пололжительные собственные числа, размажем его между $U^*$ и $U$: 
берём $\sqrt{D}$, $(U')* = U^* \sqrt{D} ; U' = \sqrt{D} U$.



$QR$ разложение: для невырожденной можно представить как произведение ортогональной на правую. Или же левой на ортогональную (через разложение транспонирования $A$).
$Q$ находится ортонормированием столбцов исходной. За $R^{-1}$ берём матрицу коэффициентов при ортогонализации (она обьратима, так как на диагонали не нули).

Теорема: можно взять корень из оператора, если он ОПС и с.ч. неотрицаительны. Сделаем это классическим способом через спектральные проекторы. 
Единственность следует из единственнсти спектрального разложения 
(можно представить другой кандидат на корень, он опс, разложить его спектрально, там проекторы, поэтому перекрёстные суммы уйдут, всё станет понятно).

Полярное ($QS$ или $SQ$) разложение: на самосопряжённую (H) положительно определённую и изометричную (U).

Док-во: $A^*A$ всегда самосопряжённый, причём положительно определённый, как и $A^*A$. Разложим его на ортогональные собственные подпространства, с.ч. больше нуля, выделив ОНБ из с.в..
Тогда исходный оператор переводит ЭТОТ ОНБ в ортонрмированную систему (но не обязательно базис за счёт нулей), так как действие его на эти векторы просто увеличивает его во сколько-то раз, что не меняет ортогональности.
Скалярный квадрат действия исходного оператора на такой вектор будет собственным числом. Нули выкинем, нормируем, дополним до любого ОНБ.

Зададим $H$ на этом ОНБ как имеющий собственные числа $\sqrt{\lambda_i}$ (то есть он получился самосопряжённым). 
$U$ будет переводить базис собственных чисел $AA^*$ (ОНБ) в результат действия $A$ на неё плюс наши новые векторы (то есть оно ортонормированно).

Тогда $A v_i = \sqrt{\lambda_i} z_i = HU v_i$, то есть получили разложение.

Единственность: разложим $A$, посчитаем $AA^* = HUU^*H* = H^2$, извлекаем корень из $A^*A$ единственным образом.
Причём если $A$ невырождено, решим через обратную матрицу к $H$, получим и $U$ тоже единственное.


Можно также $UH$, получается из $HU$ разложения через взятие обычного от матрицы $A^*$ и $H' = H^*, U' = U^*$, 
в случае невырожденности берём $H = \sqrt{A^* A}$ (правый модуль).




\section{Квадратичные формы}

Кваlратичная — билинейная симметричная (в $\sC$ — полуторалинейная), в которую подставлены одинаковые аргументы: $f(x) = \alpha (x, x)$.

В матричной форме: $x^T A x$.
Ранг формы — ранг её матрицы.

При смене координат $x = Q y$ матрица в новых кородинатах будет $Q^T A Q$.

Если элементы вне диагонали нулевые — канонический вид.

Для формы в каноническом виде пололжительный, отрицательный индексы инерции и количество нулей — количество соответствующих элементов на диагонали.

Сигнатура — это тройка $(\sigma^+(f), \sigma^-(f), \sigma_0(f))$

Нормальный вид — канонический и все элементы $\in \{-1, 0, 1\}$

Приведение к каническому виду ортогональным преобразованием: так как $A$ — симметричная, все с.ч. вещественны и можно, приведя к каноническому виду, получить:

$[V = Q^{-1} = Q^T], A = V^T \Lambda V$, где $V$ ортонормированная.

Метод Лагранжа: Последовательные невырожденные преобразования для диагонализации. 
Если нет ненулувых квадратов, делаем первый шаг:
не трогая остальные переменные, вводим $x_i = y_i + y_j, x_j = y_i - y_j$. 
Получам квадратный член и матрицу с квадратиком на диагонали из $1, 1, 1, -1$.

Если же квадрат есть, разделяем на только этот квадрат с коэффициентом и форму чисто от остальных аргументов.
Для этого выеляем полный квадрат с первым членом, где коэффициенты для остальных берём из перекрёстных членов.
Тогда в качестве новой переменной берём $y_i = \sum_j a_{ij} x_j$. Обратной матрицей преобразования будет, где в i-й строке стоит $a_{ij}$, а остальное — $\delta^i_j$.

Метод Якоби (угловые миноры кроме последнего $\neq 0$): матрца формы самосопряжена, 
так что раскладываем в $A = U^*DU \Rightarrow \Lambda = (U^{-1})^T A U^{-1}$, причём будет состоять из отношений миноров.
Тогда берём $Q = U^{-1}$.
Существует единственное такое верхнее унитреугольное преобразование, причём его можно найти через $A_{k -1} q_i = -b_i$, где $A_i$ — угловые матрицы $A$, $q_i$ столбцы $q$, $b_i$ — верхние части столбцов $A$.

Осталось доказать, что можно найти именно так:

Для n = 2 доказываем русками через разложение. 
Далее — по индукции через деление матриц на 4 части доказываем, что если очередной столбец $Q$ посчитать именно так, то будет $Q_{k + 1}^T A_{k + 1} Q_{k + 1} = D$.

Note: если ранг $n - 1$, а не $n$, проведём сначала невырожденное преобразование матрицей перестановки, получив все миноры кроме последнего не нули.



Критерий инерции квадратичный форм: любое невырожденное преобразование к каноническому виду, даёт одинаковую сигнатуру.

Докажем от противного. Во-первых, ранг не меняется при невырожденных преобразованиях. 
Запишем с два приведения формы к КВ с разным количеством пололжительных и отрицательных (но $\sigma^+ + \sigma^- = \rg f$, то есть нулевых одинаково).

НУО, $p < s$. Для любого $y, z$ системы $Q_1^{-1} \mathbb{x} = y$ и $Q_2^{-1} \mathbb{x} = z$ имеют единственное решение в силу невырожденности.

Сделаем $y_0$ — вектор из нулей в первых $p$ позициях, в остальных — что угодно. И $z_0$ — с нулями в последних $n - s$, а в первых $s$ — что угодно.

Сделаем однородную систему из $p + n - s < n$ уравнений, взяв первые $p$ уравнений из $Q_1^{-1} \mathbb{x} = y$ 
и последние $s$ из $Q_2^{-1} \mathbb{x} = z$. Тогда будет нетривиальное решение новой системы $x^*$.
Обозначим $y^* = Q_1^{-1} \mathbb{x^*}, z^* = Q_2^{-1} \mathbb{x^*}$. С одной стороны, $y^* \neq 0 \neq z^*$, так как $x^* \neq 0$.
С другой — первые $p$ и последние $s$ — нули, так как мы брали нужные уравнения из соответствующей системы.
Тогда остальные элементы — не только нули.

Но тогда перейдём к координатам в обоих $x$, получив, что $f(x^*) = g(y^*) > 0$ и $= h(z^*) < 0$ одновременно. 

Знакоопределённость формы — определяется как у матрицы.

Критерий Сильвестра: если все угловые миноры ненулевые, то: 
если все положительные, она положительно определённая, если чередуются начиная с отрицательного — отрицательно определённая,
если всё это для предыдущих и последний минор равно нулю, то полуопределённая с соответствующим знаком. Иначе — НЕопределённая.

ПВП к каноническому виду: выделяем квадратичную форму, избавляемся от перекрёстных членов ортогональным преобразованием, заменяем координаты (меняются и линейные члены тоже).
Для тех, что ненулевые, выделяем полный квадрат, делаем параллельный перенос. Причём, если ненулевой коэффициент при линейном члене, можно заменой переменной абсорбировать свободный член.

Далее появятся варианты в зависимости от того, сколько у нас ненулевых коэффицикнтов при квадратах.

\begin{enumerate}
    \item Если 3 или 2, тривиально.
    \item Если только один, то после выдерения полного квадрата при нём останется ещё линейные члены для $y$ и $z$ и свободный. 
    Выполним поворот относительно оси $OX$, чтобы ненулевым стал только коэффициент при $y$, а $z$ пропал. (Получается на угол арктангенс отношения).
\end{enumerate}

\end{document}
